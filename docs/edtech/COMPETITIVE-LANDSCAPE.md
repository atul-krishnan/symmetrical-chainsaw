# Competitive Landscape + Positioning (PolicyPilot)

## Target customers (who buys)

- B2B SaaS companies (200-2000 employees) shipping AI-enabled features or enabling internal GenAI use.
- Primary buyers: CISO / Head of Security, GRC/Compliance lead.
- Strong co-buyers: Legal/Privacy, People Ops / L&D.

## The job they hire us for

"Turn internal AI policies into role-ready training, drive completion + attestation, and produce audit-ready evidence without running a separate LMS project."

## Competitor map (what we will run into)

### 1) Compliance automation / GRC platforms (adjacent, often in the budget already)

Examples: Vanta, Drata, Secureframe, Hyperproof, AuditBoard.

- Typical customers: fast-growing B2B SaaS and regulated teams that need continuous audit evidence and customer assurance.
- They win because they: already sit in the audit workflow, collect evidence, and have executive attention.
- Their gap: workforce training is usually generic, integration-driven, or not tightly grounded in the company's actual policy text.

### 2) Compliance training libraries (strong content, weaker policy specificity)

Examples: NAVEX, Traliant, SAI360, Skillsoft, Cornerstone content catalogs.

- Typical customers: larger/regulatory-heavy orgs that want broad, standardized courses and completion reporting.
- They win because they: ship large course libraries, "legal-reviewed" content, and standard reporting.
- Their gap: company-specific AI policy nuance and fast, repeatable "policy changes -> updated training -> evidence pack" loops.

### 3) Security awareness training (phishing-first; policy training is secondary)

Examples: KnowBe4, Proofpoint Security Awareness, Hoxhunt.

- Typical customers: any org running phishing simulations and baseline awareness requirements at scale.
- They win because they: have proven completion workflows and reminder systems.
- Their gap: mapping a specific internal policy to obligations, role tracks, and audit-style attestations.

### 4) LMS/LXP (plumbing, not outcomes)

Examples: Docebo, Cornerstone LMS, Workday Learning, SAP SuccessFactors.

- Typical customers: mid-market and enterprise teams needing centralized learning assignment + reporting infrastructure.
- They win because they: are "the system of record" for learning.
- Their gap: content creation and compliance evidence packaging still becomes a project.

### 5) AI governance platforms (model governance, not workforce adoption)

Examples: Credo AI, Holistic AI, model risk tooling.

- Typical customers: AI-heavy orgs focused on model inventory, controls, and governance review processes.
- They win because they: support AI inventory, risk controls, and governance workflows.
- Their gap: training operations and measurable workforce adoption (completion + attestation) from policy text.

## Where PolicyPilot wins (wedge + differentiation)

- **Policy-grounded training**: start from your policy docs, not a generic library.
- **Role tracks out of the box**: `exec`, `builder`, `general` from one policy source.
- **Campaign engine**: publish assignments, run reminder cadences, and measure completion + attestation.
- **Evidence pack**: CSV audit rows + checksum-signed PDF summary (legal-verifiable).
- **Pilot speed**: first publish in under ~45 minutes once the policy source is ready.

## Positioning statements (pick 1 and stick to it)

1. **PolicyPilot is the policy-to-training layer for AI governance.**
2. **From AI policy docs to role-ready training in under 45 minutes (with audit-ready evidence).**
3. **Compliance training that matches your policy, not a generic course library.**

## Displacement vs. coexistence (how we sell into real stacks)

- If they already use a compliance platform (Vanta/Drata/etc.): we are the **policy-to-training + evidence export** system they attach to their compliance program.
- If they already use an LMS: we are the **campaign + evidence** layer for AI policy, and can later export/bridge results into the LMS.
- If they already use security awareness training: we do **policy-specific AI training** and keep phishing/social engineering in the SAT tool.

## Objections and crisp responses

- "We already have training." -> "Is it grounded in your AI policy clauses, role-specific, and does it produce an evidence pack your auditors accept without manual stitching?"
- "We already have Vanta/Drata." -> "Great, keep it. PolicyPilot makes the workforce adoption measurable and exportable for AI policy and internal controls."
- "We can do this in our LMS." -> "You can host content there. The hard part is generating/maintaining role tracks from policy updates and producing provable evidence under real rollout conditions."
